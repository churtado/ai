{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://192.168.1.123:8998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add86031811f4eb49a5cfcebe80a83a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TWFnaWNzQ29udHJvbGxlcldpZGdldChjaGlsZHJlbj0oVGFiKGNoaWxkcmVuPShNYW5hZ2VTZXNzaW9uV2lkZ2V0KGNoaWxkcmVuPShIVE1MKHZhbHVlPXUnPGJyLz4nKSwgSFRNTCh2YWx1ZT3igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint http://192.168.1.123:8998/\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>spark</td><td>idle</td><td></td><td></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvacText: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:25\n",
      "res1: Int = 1\n"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "val hvacText = sc.parallelize(Array(1, 2, 3, 4))\n",
    "hvacText.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "org.apache.spark.sql.AnalysisException: java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient;\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:194)\n",
      "  at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)\n",
      "  at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:39)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:54)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder$$anon$1.<init>(HiveSessionStateBuilder.scala:69)\n",
      "  at org.apache.spark.sql.hive.HiveSessionStateBuilder.analyzer(HiveSessionStateBuilder.scala:69)\n",
      "  at org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "  at org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "  at org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:79)\n",
      "  at org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:79)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n",
      "  at org.apache.spark.sql.SparkSession.baseRelationToDataFrame(SparkSession.scala:431)\n",
      "  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:233)\n",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\n",
      "  ... 51 elided\n",
      "Caused by: java.lang.RuntimeException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n",
      "  at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:180)\n",
      "  at org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:114)\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "  at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "  at org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)\n",
      "  at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:385)\n",
      "  at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:287)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:195)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\n",
      "  ... 71 more\n",
      "Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient\n",
      "  at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1523)\n",
      "  at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)\n",
      "  at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n",
      "  at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n",
      "  at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n",
      "  at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n",
      "  ... 86 more\n",
      "Caused by: java.lang.reflect.InvocationTargetException: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:298)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n",
      "\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:76)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:136)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:57)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n",
      "\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:180)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:114)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)\n",
      "\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:385)\n",
      "\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:287)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:194)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:39)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder$$anon$1.<init>(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.analyzer(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "\tat org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:79)\n",
      "\tat org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n",
      "\tat org.apache.spark.sql.SparkSession.baseRelationToDataFrame(SparkSession.scala:431)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:233)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\n",
      "\tat <init>(<console>:28)\n",
      "\tat <init>(<console>:33)\n",
      "\tat <init>(<console>:35)\n",
      "\tat <init>(<console>:37)\n",
      "\tat <init>(<console>:39)\n",
      "\tat <init>(<console>:41)\n",
      "\tat <init>(<console>:43)\n",
      "\tat <init>(<console>:45)\n",
      "\tat <init>(<console>:47)\n",
      "\tat <init>(<console>:49)\n",
      "\tat .<init>(<console>:53)\n",
      "\tat .<clinit>(<console>)\n",
      "\tat .$print$lzycompute(<console>:7)\n",
      "\tat .$print(<console>:6)\n",
      "\tat $print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n",
      "\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n",
      "\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n",
      "\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n",
      "\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n",
      "\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n",
      "\tat org.apache.livy.repl.SparkInterpreter.interpret(SparkInterpreter.scala:120)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$executeLine$1.apply(AbstractSparkInterpreter.scala:303)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$executeLine$1.apply(AbstractSparkInterpreter.scala:303)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n",
      "\tat scala.Console$.withOut(Console.scala:65)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.executeLine(AbstractSparkInterpreter.scala:302)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.org$apache$livy$repl$AbstractSparkInterpreter$$executeLines(AbstractSparkInterpreter.scala:242)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$execute$1.apply(AbstractSparkInterpreter.scala:110)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$execute$1.apply(AbstractSparkInterpreter.scala:107)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.restoreContextClassLoader(AbstractSparkInterpreter.scala:340)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.execute(AbstractSparkInterpreter.scala:107)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$7.apply(Session.scala:274)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$7.apply(Session.scala:272)\n",
      "\tat scala.Option.map(Option.scala:146)\n",
      "\tat org.apache.livy.repl.Session.org$apache$livy$repl$Session$$executeCode(Session.scala:272)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply$mcV$sp(Session.scala:168)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 154 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /usr/local/livy/bin/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 151 more\n",
      "------\n",
      "\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "  at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "  at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n",
      "  ... 92 more\n",
      "Caused by: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:298)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n",
      "\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:76)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:136)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:57)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n",
      "\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:180)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:114)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)\n",
      "\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:385)\n",
      "\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:287)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:194)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:39)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder$$anon$1.<init>(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.analyzer(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "\tat org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:79)\n",
      "\tat org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n",
      "\tat org.apache.spark.sql.SparkSession.baseRelationToDataFrame(SparkSession.scala:431)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:233)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\n",
      "\tat <init>(<console>:28)\n",
      "\tat <init>(<console>:33)\n",
      "\tat <init>(<console>:35)\n",
      "\tat <init>(<console>:37)\n",
      "\tat <init>(<console>:39)\n",
      "\tat <init>(<console>:41)\n",
      "\tat <init>(<console>:43)\n",
      "\tat <init>(<console>:45)\n",
      "\tat <init>(<console>:47)\n",
      "\tat <init>(<console>:49)\n",
      "\tat .<init>(<console>:53)\n",
      "\tat .<clinit>(<console>)\n",
      "\tat .$print$lzycompute(<console>:7)\n",
      "\tat .$print(<console>:6)\n",
      "\tat $print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n",
      "\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n",
      "\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n",
      "\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n",
      "\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n",
      "\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n",
      "\tat org.apache.livy.repl.SparkInterpreter.interpret(SparkInterpreter.scala:120)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$executeLine$1.apply(AbstractSparkInterpreter.scala:303)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$executeLine$1.apply(AbstractSparkInterpreter.scala:303)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n",
      "\tat scala.Console$.withOut(Console.scala:65)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.executeLine(AbstractSparkInterpreter.scala:302)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.org$apache$livy$repl$AbstractSparkInterpreter$$executeLines(AbstractSparkInterpreter.scala:242)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$execute$1.apply(AbstractSparkInterpreter.scala:110)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$execute$1.apply(AbstractSparkInterpreter.scala:107)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.restoreContextClassLoader(AbstractSparkInterpreter.scala:340)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.execute(AbstractSparkInterpreter.scala:107)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$7.apply(Session.scala:274)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$7.apply(Session.scala:272)\n",
      "\tat scala.Option.map(Option.scala:146)\n",
      "\tat org.apache.livy.repl.Session.org$apache$livy$repl$Session$$executeCode(Session.scala:272)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply$mcV$sp(Session.scala:168)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 154 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /usr/local/livy/bin/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 151 more\n",
      "------\n",
      "\n",
      "  at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:436)\n",
      "  at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:788)\n",
      "  at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n",
      "  at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n",
      "  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "  at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "  at javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n",
      "  at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n",
      "  at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n",
      "  at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n",
      "  at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n",
      "  at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n",
      "  at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n",
      "  at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n",
      "  at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:76)\n",
      "  at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:136)\n",
      "  at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:57)\n",
      "  at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n",
      "  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n",
      "  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n",
      "  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n",
      "  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n",
      "  at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\n",
      "  at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n",
      "  at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n",
      "  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)\n",
      "  at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)\n",
      "  ... 97 more\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "java.sql.SQLException: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "\tat org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:298)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n",
      "\tat org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:333)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:202)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1965)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1960)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1166)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:808)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:701)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:365)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:394)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:291)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:258)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:76)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:136)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:57)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:66)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStore(HiveMetaStore.java:593)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:571)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:624)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:461)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:66)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:72)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:5762)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:199)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:74)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1521)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:86)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:132)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3005)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3024)\n",
      "\tat org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:503)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:180)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.<init>(HiveClientImpl.scala:114)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)\n",
      "\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:385)\n",
      "\tat org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:287)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:195)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:194)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.externalCatalog(HiveSessionStateBuilder.scala:39)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:54)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder$$anon$1.<init>(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.analyzer(HiveSessionStateBuilder.scala:69)\n",
      "\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "\tat org.apache.spark.sql.internal.BaseSessionStateBuilder$$anonfun$build$2.apply(BaseSessionStateBuilder.scala:293)\n",
      "\tat org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:79)\n",
      "\tat org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n",
      "\tat org.apache.spark.sql.SparkSession.baseRelationToDataFrame(SparkSession.scala:431)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:233)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\n",
      "\tat <init>(<console>:28)\n",
      "\tat <init>(<console>:33)\n",
      "\tat <init>(<console>:35)\n",
      "\tat <init>(<console>:37)\n",
      "\tat <init>(<console>:39)\n",
      "\tat <init>(<console>:41)\n",
      "\tat <init>(<console>:43)\n",
      "\tat <init>(<console>:45)\n",
      "\tat <init>(<console>:47)\n",
      "\tat <init>(<console>:49)\n",
      "\tat .<init>(<console>:53)\n",
      "\tat .<clinit>(<console>)\n",
      "\tat .$print$lzycompute(<console>:7)\n",
      "\tat .$print(<console>:6)\n",
      "\tat $print(<console>)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n",
      "\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n",
      "\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n",
      "\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n",
      "\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n",
      "\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n",
      "\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n",
      "\tat org.apache.livy.repl.SparkInterpreter.interpret(SparkInterpreter.scala:120)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$executeLine$1.apply(AbstractSparkInterpreter.scala:303)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$executeLine$1.apply(AbstractSparkInterpreter.scala:303)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n",
      "\tat scala.Console$.withOut(Console.scala:65)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.executeLine(AbstractSparkInterpreter.scala:302)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.org$apache$livy$repl$AbstractSparkInterpreter$$executeLines(AbstractSparkInterpreter.scala:242)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$execute$1.apply(AbstractSparkInterpreter.scala:110)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter$$anonfun$execute$1.apply(AbstractSparkInterpreter.scala:107)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.restoreContextClassLoader(AbstractSparkInterpreter.scala:340)\n",
      "\tat org.apache.livy.repl.AbstractSparkInterpreter.execute(AbstractSparkInterpreter.scala:107)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$7.apply(Session.scala:274)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$7.apply(Session.scala:272)\n",
      "\tat scala.Option.map(Option.scala:146)\n",
      "\tat org.apache.livy.repl.Session.org$apache$livy$repl$Session$$executeCode(Session.scala:272)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply$mcV$sp(Session.scala:168)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163)\n",
      "\tat org.apache.livy.repl.Session$$anonfun$execute$1.apply(Session.scala:163)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "\t... 154 more\n",
      "Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /usr/local/livy/bin/metastore_db.\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "\tat org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "\tat org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "\t... 151 more\n",
      "------\n",
      "\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "  at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "  at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "  at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "  at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "  at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:501)\n",
      "  at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:298)\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "  at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "  at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:631)\n",
      "  at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "  at org.datanucleus.NucleusContext.createStoreManagerForProperties(NucleusContext.java:1187)\n",
      "  at org.datanucleus.NucleusContext.initialise(NucleusContext.java:356)\n",
      "  at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:775)\n",
      "  ... 126 more\n",
      "Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "  at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)\n",
      "  at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "  at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)\n",
      "  at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "  at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)\n",
      "  at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)\n",
      "  at java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "  at java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "  at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "  at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "  ... 138 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Failed to start database 'metastore_db' with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6aa2e1ac, see the next exception for details.\n",
      "  at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)\n",
      "  ... 154 more\n",
      "Caused by: org.apache.derby.iapi.error.StandardException: Another instance of Derby may have already booted the database /usr/local/livy/bin/metastore_db.\n",
      "  at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "  at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)\n",
      "  at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)\n",
      "  at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)\n",
      "  at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "  at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "  at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)\n",
      "  at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "  at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "  at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)\n",
      "  at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)\n",
      "  at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)\n",
      "  at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)\n",
      "  at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)\n",
      "  at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)\n",
      "  at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)\n",
      "  at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "  at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)\n",
      "  at java.security.AccessController.doPrivileged(Native Method)\n",
      "  at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)\n",
      "  ... 151 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "import org.apache.spark.sql.SQLContext\n",
    "\n",
    "val sqlContext = new SQLContext(sc)\n",
    "val df = sqlContext.read.format(\"com.crealytics.spark.excel\").option(\"sheetName\", \"orders\").option(\"useHeader\", \"true\").option(\"inferSchema\", \"false\").load(\"/home/churtado/notebooks/data/superstore.xls\")\n",
    "df.createTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>orders</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database tableName  isTemporary\n",
       "0      NaT    orders         True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "SHOW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>CA-2014-115812</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>BH-11710</td>\n",
       "      <td>Brosina Hoffman</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90032</td>\n",
       "      <td>West</td>\n",
       "      <td>FUR-FU-10001487</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>Eldon Expressions Wood and Plastic Desk Access...</td>\n",
       "      <td>48.8600</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>CA-2014-115812</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>BH-11710</td>\n",
       "      <td>Brosina Hoffman</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90032</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-AR-10002833</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>Newell 322</td>\n",
       "      <td>7.2800</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>CA-2014-115812</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>BH-11710</td>\n",
       "      <td>Brosina Hoffman</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90032</td>\n",
       "      <td>West</td>\n",
       "      <td>TEC-PH-10002275</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Phones</td>\n",
       "      <td>Mitel 5320 IP Phone VoIP phone</td>\n",
       "      <td>907.1520</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>90.7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>CA-2014-115812</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>BH-11710</td>\n",
       "      <td>Brosina Hoffman</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90032</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-BI-10003910</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>DXL Angle-View Binders with Locking Rings by S...</td>\n",
       "      <td>18.5040</td>\n",
       "      <td>3</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>CA-2014-115812</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>BH-11710</td>\n",
       "      <td>Brosina Hoffman</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90032</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-AP-10002892</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Belkin F5C206VTEL 6 Outlet Surge</td>\n",
       "      <td>114.9000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.4700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2016-152156 2016-11-08 2016-11-11    Second Class    CG-12520   \n",
       "1       2  CA-2016-152156 2016-11-08 2016-11-11    Second Class    CG-12520   \n",
       "2       3  CA-2016-138688 2016-06-12 2016-06-16    Second Class    DV-13045   \n",
       "3       4  US-2015-108966 2015-10-11 2015-10-18  Standard Class    SO-20335   \n",
       "4       5  US-2015-108966 2015-10-11 2015-10-18  Standard Class    SO-20335   \n",
       "5       6  CA-2014-115812 2014-06-09 2014-06-14  Standard Class    BH-11710   \n",
       "6       7  CA-2014-115812 2014-06-09 2014-06-14  Standard Class    BH-11710   \n",
       "7       8  CA-2014-115812 2014-06-09 2014-06-14  Standard Class    BH-11710   \n",
       "8       9  CA-2014-115812 2014-06-09 2014-06-14  Standard Class    BH-11710   \n",
       "9      10  CA-2014-115812 2014-06-09 2014-06-14  Standard Class    BH-11710   \n",
       "\n",
       "     Customer Name    Segment        Country             City    ...     \\\n",
       "0      Claire Gute   Consumer  United States        Henderson    ...      \n",
       "1      Claire Gute   Consumer  United States        Henderson    ...      \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles    ...      \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale    ...      \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale    ...      \n",
       "5  Brosina Hoffman   Consumer  United States      Los Angeles    ...      \n",
       "6  Brosina Hoffman   Consumer  United States      Los Angeles    ...      \n",
       "7  Brosina Hoffman   Consumer  United States      Los Angeles    ...      \n",
       "8  Brosina Hoffman   Consumer  United States      Los Angeles    ...      \n",
       "9  Brosina Hoffman   Consumer  United States      Los Angeles    ...      \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "5       90032    West  FUR-FU-10001487        Furniture  Furnishings   \n",
       "6       90032    West  OFF-AR-10002833  Office Supplies          Art   \n",
       "7       90032    West  TEC-PH-10002275       Technology       Phones   \n",
       "8       90032    West  OFF-BI-10003910  Office Supplies      Binders   \n",
       "9       90032    West  OFF-AP-10002892  Office Supplies   Appliances   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "5  Eldon Expressions Wood and Plastic Desk Access...   48.8600         7   \n",
       "6                                         Newell 322    7.2800         4   \n",
       "7                     Mitel 5320 IP Phone VoIP phone  907.1520         6   \n",
       "8  DXL Angle-View Binders with Locking Rings by S...   18.5040         3   \n",
       "9                   Belkin F5C206VTEL 6 Outlet Surge  114.9000         5   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "5      0.00   14.1694  \n",
       "6      0.00    1.9656  \n",
       "7      0.20   90.7152  \n",
       "8      0.20    5.7825  \n",
       "9      0.00   34.4700  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql -o df_orders --maxrows 10\n",
    "SELECT * FROM orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735fccc9bc2e48beb62419fd1e42cac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oSEJveChjaGlsZHJlbj0oSFRNTCh2YWx1ZT11J1R5cGU6JyksIEJ1dHRvbihkZXNjcmlwdGlvbj11J1RhYmxlJywgbGF5b3V0PUxheW91dCh3aWR0aD11JzcwcHgnKSzigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b45ff1125a74a8b9977c8b535986d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75f7bb1609a4b7aac888009b7d33a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AutoVizWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autovizwidget.widget.utils import display_dataframe\n",
    "display_dataframe(df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/4.embed\" height=\"450px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='churtado', api_key='iaMRV6ydU9Ove5Yfy0R7')\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "fips = ['06021', '06023', '06027',\n",
    "        '06029', '06033', '06059',\n",
    "        '06047', '06049', '06051',\n",
    "        '06055', '06061']\n",
    "values = range(len(fips))\n",
    "\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "py.iplot(fig, filename='choropleth of some cali counties - full usa scope')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
