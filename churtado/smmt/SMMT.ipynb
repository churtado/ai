{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "https://otexts.org/fpp2/intro.html  \n",
    "https://machinelearningmastery.com/time-series-forecast-study-python-annual-water-usage-baltimore/  \n",
    "also: https://machinelearningmastery.com/time-series-forecast-case-study-python-monthly-armed-robberies-boston/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Use this command to convert the notebook into a slideshow that can be presented:\n",
    "\n",
    "\n",
    " jupyter nbconvert --to slides --ServePostProcessor.port=8910 --ServePostProcessor.ip='0.0.0.0' --post serve /home/churtado/notebooks/churtado/smmt/SMMT.ipynb  \n",
    "   \n",
    "Access the slides here:  \n",
    "http://192.168.1.123:8910/SMMT.slides.html#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='churtado', api_key='iaMRV6ydU9Ove5Yfy0R7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "http://192.168.1.123:8998/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b653db0d6b34e1da5608e7bf90321cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TWFnaWNzQ29udHJvbGxlcldpZGdldChjaGlsZHJlbj0oVGFiKGNoaWxkcmVuPShNYW5hZ2VTZXNzaW9uV2lkZ2V0KGNoaWxkcmVuPShIVE1MKHZhbHVlPXUnPGJyLz4nKSwgSFRNTCh2YWx1ZT3igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint http://192.168.1.123:8998/\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>11</td><td>None</td><td>spark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: there was one deprecation warning; re-run with -deprecation for details\n",
      "sqlContext: org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@674059af\n",
      "df: org.apache.spark.sql.DataFrame = [date: string, passenger_cars: string]\n"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)\n",
    "\n",
    "val df = sqlContext.read.format(\"com.crealytics.spark.excel\").option(\"sheetName\", \"pc\").option(\"useHeader\", \"true\").option(\"inferSchema\", \"false\").load(\"/home/churtado/notebooks/data/smmt.xls\")\n",
    "df.createTempView(\"pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>cleaned_taxes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>pc</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database      tableName  isTemporary\n",
       "0  default  cleaned_taxes        False\n",
       "1                      pc         True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "SHOW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>passenger_cars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>234945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>192649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>167911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  passenger_cars\n",
       "0 2018-06-30          234945\n",
       "1 2018-05-31          192649\n",
       "2 2018-04-30          167911"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "SELECT * from pc limit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql\n",
    "DROP TABLE IF EXISTS passenger_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%spark -c sql \n",
    "\n",
    "CREATE TABLE passenger_cars AS\n",
    "SELECT \n",
    " date, \n",
    " passenger_cars\n",
    "FROM pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%spark -c sql -q -o df_passenger_cars\n",
    "SELECT * from pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ARIMA Forecast using SSMT data\n",
    "  \n",
    "* 2 columns: total passenger cars sold, and date\n",
    "* From january 2013 until june 2018\n",
    "* Monthly level (last day of each month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When decomposing a time series, there are 2 components to look out for:  \n",
    "  \n",
    "Systematic: Components of the time series that have consistency or recurrence and can be described and modeled.  \n",
    "Non-Systematic: Components of the time series that cannot be directly modeled.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Concretely, the components are:  \n",
    "  \n",
    "    Level: The average value in the series.  \n",
    "    Trend: The increasing or decreasing value in the series.  \n",
    "    Seasonality: The repeating short-term cycle in the series.  \n",
    "    Noise: The random variation in the series.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's try to decompose it. First set up our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "df_passenger_cars_decomp = df_passenger_cars\n",
    "df_passenger_cars_decomp['date'] = pd.to_datetime(df_passenger_cars_decomp['date'])\n",
    "df_passenger_cars_decomp = df_passenger_cars_decomp.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_cars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>234945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>192649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>167911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>474069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-28</th>\n",
       "      <td>80805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            passenger_cars\n",
       "date                      \n",
       "2018-06-30          234945\n",
       "2018-05-31          192649\n",
       "2018-04-30          167911\n",
       "2018-03-31          474069\n",
       "2018-02-28           80805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_passenger_cars_decomp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We're looking at this breakdown assuming an additive model first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result_additive = seasonal_decompose(df_passenger_cars_decomp, model='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We'll take the original values from our statsmodel decomp and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1_observed = go.Scatter(\n",
    "    x = result_additive.observed.index,\n",
    "    y = result_additive.observed.values,\n",
    "    xaxis='x',\n",
    "    yaxis='y',\n",
    "    name='trend'\n",
    ")\n",
    "data_observed = [trace1_observed]\n",
    "layout_observed = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500,\n",
    "    xaxis=dict(\n",
    "        domain=[0, 1]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/24.embed\" height=\"500px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_data = go.Figure(data=data_observed, layout=layout_observed)\n",
    "py.iplot(fig_data, filename='observed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1_additive = go.Scatter(\n",
    "    x = result_additive.trend.index,\n",
    "    y = result_additive.trend.values,\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    name='trend'\n",
    ")\n",
    "trace2_additive = go.Scatter(\n",
    "    x = result_additive.seasonal.index,\n",
    "    y = result_additive.seasonal.values,\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    name='seasonal'\n",
    ")\n",
    "trace3_additive = go.Scatter(\n",
    "    x = result_additive.resid.index,\n",
    "    y = result_additive.resid.values,\n",
    "    xaxis='x',\n",
    "    yaxis='y',\n",
    "    name='residual'\n",
    ")\n",
    "trace4_additive = go.Scatter(\n",
    "    x = result_additive.observed.index,\n",
    "    y = result_additive.observed.values,\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    name='observed'\n",
    ")\n",
    "data_additive = [trace4_additive, trace1_additive, trace2_additive, trace3_additive]\n",
    "layout_additive = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500,\n",
    "    xaxis=dict(\n",
    "        domain=[0, 1]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.23]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0.26, 0.48],\n",
    "        anchor='y2'\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.52, 0.73]\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.76, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For reference we'll decompose the dataset using a naive decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/20.embed\" height=\"500px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_additive = go.Figure(data=data_additive, layout=layout_additive)\n",
    "py.iplot(fig_additive, filename='additive-subplots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we'll decompose using a naive multiplicative model  \n",
    "  \n",
    "However, as mentioned before, an additive model may be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result_mult = seasonal_decompose(df_passenger_cars_decomp, model='multiplicative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1_mult = go.Scatter(\n",
    "    x = result_mult.trend.index,\n",
    "    y = result_mult.trend.values,\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    name='trend'\n",
    ")\n",
    "trace2_mult = go.Scatter(\n",
    "    x = result_mult.seasonal.index,\n",
    "    y = result_mult.seasonal.values,\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    name='seasonal'\n",
    ")\n",
    "trace3_mult = go.Scatter(\n",
    "    x = result_mult.resid.index,\n",
    "    y = result_mult.resid.values,\n",
    "    xaxis='x',\n",
    "    yaxis='y',\n",
    "    name='residual'\n",
    ")\n",
    "trace4_mult = go.Scatter(\n",
    "    x = result_mult.observed.index,\n",
    "    y = result_mult.observed.values,\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    name='observed'\n",
    ")\n",
    "data_mult = [trace4_mult, trace1_mult, trace2_mult, trace3_mult]\n",
    "layout_mult = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500,\n",
    "    xaxis=dict(\n",
    "        domain=[0, 1]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.23]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0.26, 0.48],\n",
    "        anchor='y2'\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.52, 0.73]\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.76, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/22.embed\" height=\"500px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_mult = go.Figure(data=data_mult, layout=layout_mult)\n",
    "py.iplot(fig_mult, filename='multiplicative-subplots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use of a naive model is generally discouraged, so we've used STL decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll now present STL decomposition (Seasonal and Trend decomposition using Loess)  \n",
    "  \n",
    "For more information see https://otexts.org/fpp2/stl.html  \n",
    "The STL decomp package used is here: https://github.com/jrmontag/STLDecompose\n",
    "\n",
    "STL decomp requires no missing values, so interpolation may be required. Fortunately, there are none in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from stldecompose import decompose, forecast\n",
    "from stldecompose.forecast_funcs import (naive, drift, mean, seasonal_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "stl = decompose(df_passenger_cars_decomp, period=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1_stl = go.Scatter(\n",
    "    x = stl.trend.index,\n",
    "    y = stl.trend.values,\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    name='trend'\n",
    ")\n",
    "trace2_stl = go.Scatter(\n",
    "    x = stl.seasonal.index,\n",
    "    y = stl.seasonal.values,\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    name='seasonal'\n",
    ")\n",
    "trace3_stl = go.Scatter(\n",
    "    x = stl.resid.index,\n",
    "    y = stl.resid.values,\n",
    "    xaxis='x',\n",
    "    yaxis='y',\n",
    "    name='residual'\n",
    ")\n",
    "trace4_stl = go.Scatter(\n",
    "    x = stl.observed.index,\n",
    "    y = stl.observed.values,\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    name='observed'\n",
    ")\n",
    "data_stl = [trace4_stl, trace1_stl, trace2_stl, trace3_stl]\n",
    "layout_stl = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=500,\n",
    "    xaxis=dict(\n",
    "        domain=[0, 1]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.23]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0.26, 0.48],\n",
    "        anchor='y2'\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.52, 0.73]\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.76, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/26.embed\" height=\"500px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_stl = go.Figure(data=data_stl, layout=layout_stl)\n",
    "py.iplot(fig_stl, filename='stl-decomp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Strong seasonal component  \n",
    "* Neither frequency nor amplitude change dramatically over time.  \n",
    "* Trend is not linear, but this behavior could be part of a larger cycle, difficult to tell without more data  \n",
    "* Trend doesn't seem to be multiplicative, so an additive model may be appropriate for decomposition and forecasting  \n",
    "* Magnitude of sales seems quite stable over the time period for which there is data\n",
    "* Overall, there are patterns in the data that indicate a forecast model is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "month = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "         'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Create and style traces\n",
    "trace0_seasonal = go.Scatter(\n",
    "    x = month,\n",
    "    y = df_passenger_cars_decomp.loc['2013'].values,\n",
    "    name = '2013',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "trace1_seasonal = go.Scatter(\n",
    "    x = month,\n",
    "    y = df_passenger_cars_decomp.loc['2014'].values,\n",
    "    name = '2014',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "trace2_seasonal = go.Scatter(\n",
    "    x = month,\n",
    "    y = df_passenger_cars_decomp.loc['2015'].values,\n",
    "    name = '2015',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "trace3_seasonal = go.Scatter(\n",
    "    x = month,\n",
    "    y = df_passenger_cars_decomp.loc['2016'].values,\n",
    "    name = '2016',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "trace4_seasonal = go.Scatter(\n",
    "    x = month,\n",
    "    y = df_passenger_cars_decomp.loc['2017'].values,\n",
    "    name = '2017',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "trace5_seasonal = go.Scatter(\n",
    "    x = month,\n",
    "    y = df_passenger_cars_decomp.loc['2018'].values,\n",
    "    name = '2018',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "data_seasonal = [trace0_seasonal, trace1_seasonal, trace2_seasonal, trace3_seasonal, trace4_seasonal, trace5_seasonal]\n",
    "\n",
    "# Edit the layout\n",
    "layout_seasonal = dict(title = 'Seasonal Plot Passenger Cars',\n",
    "              xaxis = dict(title = 'Month'),\n",
    "              yaxis = dict(title = 'Passenger Cars Sold'),\n",
    "              #showlegend=False\n",
    "              )\n",
    "\n",
    "fig_seasonal = dict(data=data_seasonal, layout=layout_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/30.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig_seasonal, filename='seasonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Seasonal plot shows peaks in April and October, valleys in May and November  \n",
    "* Slight uptick in July and December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "month = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "         'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "data = [\n",
    "    go.Scatterpolar(\n",
    "      r = df_passenger_cars_decomp.loc['2013'].values,\n",
    "      theta = month,\n",
    "      name = '2013'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "      r = df_passenger_cars_decomp.loc['2014'].values,\n",
    "      theta = month,\n",
    "      name = '2014'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "      r = df_passenger_cars_decomp.loc['2015'].values,\n",
    "      theta = month,\n",
    "      name = '2015'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "      r = df_passenger_cars_decomp.loc['2016'].values,\n",
    "      theta = month,\n",
    "      name = '2016'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "      r = df_passenger_cars_decomp.loc['2017'].values,\n",
    "      theta = month,\n",
    "      name = '2017'\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "      r = df_passenger_cars_decomp.loc['2018'].values,\n",
    "      theta = month,\n",
    "      name = '2018'\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "  polar = dict(\n",
    "    radialaxis = dict(\n",
    "      visible = False,\n",
    "      range = [0, 600000]\n",
    "    )\n",
    "  ),\n",
    "  showlegend = False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/35.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig, filename = \"seasonal-polar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Radial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "month_seasonal_sub = [2013,2014,2015,2016,2017,2018]\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==1].values,\n",
    "    name = 'January'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==2].values,\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    name = 'February'\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==3].values,\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    name = 'March'\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==4].values,\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    name = 'April'\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/47.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig, filename='sub-season-t1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==5].values,\n",
    "    name = 'May'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==6].values,\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    name = 'June'\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==7].values,\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    name = 'July'\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==8].values,\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    name = 'August'\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/45.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig, filename='sub-season-t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==9].values,\n",
    "    name = 'September'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==10].values,\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    name = 'October'\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==11].values,\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    name = 'November'\n",
    ")\n",
    "trace4 = go.Scatter(\n",
    "    x=month_seasonal_sub,\n",
    "    y=df_passenger_cars_decomp.iloc[::-1][df_passenger_cars_decomp.index.month==12].values,\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    name = 'December'\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/43.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig, filename='sub-season-t3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a good starting point for understanding autocorrelation plots:  \n",
    "https://stats.stackexchange.com/questions/101467/how-to-interpret-autocorrelation\n",
    "  \n",
    "Quoting from the article:  \n",
    "...Those plots are showing you the correlation of the series with itself, lagged by x time units. So imagine taking your time series of length T, copying it, and deleting the first observation of copy#1 and the last observation of copy#2. Now you have two series of length T−1 for which you calculate a correlation coefficient. This is the value of of the vertical axis at x=1 in your plots. It represents the correlation of the series lagged by one time unit. You go on and do this for all possible time lags x\n",
    "\n",
    "and this defines the plot.\n",
    "\n",
    "The answer to your question of what is needed to report a pattern is dependent on what pattern you would like to report. But quantitatively speaking, you have exactly what I just described: the correlation coefficient at different lags of the series. You can extract these numerical values by issuing the command...\n",
    "\n",
    "The correlation coefficient is defined as:  \n",
    "https://www.dummies.com/education/math/statistics/how-to-interpret-a-correlation-coefficient-r/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will now try to run a naive forecast on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Naive forecasts just take the last value and extend it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll start the forecasting exercise by first creating a test harness. For this we'll split the data set into a training and validation set, and we'll develop models that will give a baseline for effective forecasting.  \n",
    "  \n",
    "In order to do this, we'll split out the last 10 values from the data set and use that to validate the model. If our model can predict these last 10 values well, then it's a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 56, Validation 10\n"
     ]
    }
   ],
   "source": [
    "series = df_passenger_cars_decomp\n",
    "split_point = len(series) - 10\n",
    "dataset, validation = series[0:split_point], series[split_point:]\n",
    "\n",
    "print('Dataset %d, Validation %d' % (len(dataset), len(validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will evaluate the performance of predictions using the root mean squared error (RMSE). This will give more weight to predictions that are grossly wrong and will have the same units as the original data. We'll be doing what's called a naive forecast. We'll take the last observed value and use that as our next forecasted value, or prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Candidate models will be evaluated using walk-forward validation.\n",
    "\n",
    "This is because a rolling-forecast type model is required from the problem definition. This is where one-step forecasts are needed given all available data.\n",
    "\n",
    "The walk-forward validation will work as follows:\n",
    "\n",
    "    * The first 50% of the dataset will be held back to train the model.\n",
    "    * The remaining 50% of the dataset will be iterated and test the model.\n",
    "    * For each step in the test dataset:\n",
    "        * A model will be trained.\n",
    "        * A one-step prediction made and the prediction stored for later evaluation.\n",
    "        * The actual observation from the test dataset will be added to the training dataset for the next iteration.\n",
    "    * The predictions made during the enumeration of the test dataset will be evaluated and an RMSE score reported.\n",
    "\n",
    "Given the small size of the data, we will allow a model to be re-trained given all available data prior to each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Predicted=177664.000, Expected=462517\n",
      ">Predicted=462517.000, Expected=79060\n",
      ">Predicted=79060.000, Expected=178420\n",
      ">Predicted=178420.000, Expected=257817\n",
      ">Predicted=257817.000, Expected=198706\n",
      ">Predicted=198706.000, Expected=185778\n",
      ">Predicted=185778.000, Expected=492774\n",
      ">Predicted=492774.000, Expected=76958\n",
      ">Predicted=76958.000, Expected=164856\n",
      ">Predicted=164856.000, Expected=166198\n",
      ">Predicted=166198.000, Expected=172327\n",
      ">Predicted=172327.000, Expected=179714\n",
      ">Predicted=179714.000, Expected=425861\n",
      ">Predicted=425861.000, Expected=72163\n",
      ">Predicted=72163.000, Expected=172907\n",
      ">Predicted=172907.000, Expected=228291\n",
      ">Predicted=228291.000, Expected=194032\n",
      ">Predicted=194032.000, Expected=176820\n",
      ">Predicted=176820.000, Expected=464824\n",
      ">Predicted=464824.000, Expected=68736\n",
      ">Predicted=68736.000, Expected=154562\n",
      ">Predicted=154562.000, Expected=152918\n",
      ">Predicted=152918.000, Expected=159581\n",
      ">Predicted=159581.000, Expected=157314\n",
      ">Predicted=157314.000, Expected=403136\n",
      ">Predicted=403136.000, Expected=65937\n",
      ">Predicted=65937.000, Expected=162228\n",
      ">Predicted=162228.000, Expected=214957\n",
      ">Predicted=214957.000, Expected=180111\n",
      ">Predicted=180111.000, Expected=163357\n",
      ">Predicted=163357.000, Expected=394806\n",
      ">Predicted=394806.000, Expected=66749\n",
      ">Predicted=66749.000, Expected=143643\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train] # this is our training dataset\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "    # predict\n",
    "    yhat = history[-1] # get the last value from the training data\n",
    "    predictions.append(yhat) # append that last value from the training data as the first prediction\n",
    "    # observation\n",
    "    obs = test[i] # this is the actual value vs the forecasted that was appended to the predictions list\n",
    "    history.append(obs) # append the observed value in the history\n",
    "    print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 200408.425\n"
     ]
    }
   ],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our root mean square error is roughly 200k units (passenger cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's generate some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       passenger_cars\n",
      "count       66.000000\n",
      "mean    210940.484848\n",
      "std     123740.275669\n",
      "min      65937.000000\n",
      "25%     157533.500000\n",
      "50%     177843.000000\n",
      "75%     212114.000000\n",
      "max     562337.000000\n"
     ]
    }
   ],
   "source": [
    "print(series.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of observations matches the expectation, so we're handling the data correctly\n",
    "* Meas is about 200K, which is our level in the series\n",
    "* Std dev is roughly half the mean, so we can expect a reasonable amount of oscillation around the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at a density plot of the observed values in our series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = series.values\n",
    "data = [go.Histogram(x=x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado/51.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(data, filename='basic histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are roughly centered around the mean, and long right tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at a normalized histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = [go.Histogram(x=series.values, histnorm='probability')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# plotly free only allows 25 images. fuck\n",
    "plotly.tools.set_credentials_file(username='churtado_mazepoint', api_key='u7rxs8F6GDdGs2P5E2Tz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(data, filename='normalized_histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Roughly half the values hover around 200k mark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at a density plot. Because of a defficiency in numpy, we're sending large numbers that internally are getting converted to NaN's or INF's. We'll apply standardization to the series and use that for the density plot.\n",
    "\n",
    "See: https://stackoverflow.com/questions/14470012/scipy-optimize-curvefit-array-must-not-contain-infs-or-nans/36390482#36390482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = series.values # getting the values\n",
    "x = (x - np.mean(x, axis=0)) / np.std(x, axis=0) # normalizing the values\n",
    "x = np.transpose(x)\n",
    "\n",
    "hist_data = x\n",
    "\n",
    "group_labels = ['distplot']\n",
    "\n",
    "fig_dist = ff.create_distplot(hist_data, group_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig_dist, filename='Basic Distplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Again, long right tail\n",
    "* Perhaps a double Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "x_data = [2013,2014,2015,2016,2017,2018]\n",
    "\n",
    "y0 = series[\"2013\"].values\n",
    "y1 = series[\"2014\"].values\n",
    "y2 = series[\"2015\"].values\n",
    "y3 = series[\"2016\"].values\n",
    "y4 = series[\"2017\"].values\n",
    "y5 = series[\"2018\"].values\n",
    "\n",
    "y_data = [y0,y1,y2,y3,y4,y5]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', \n",
    "          'rgba(255, 144, 14, 0.5)', \n",
    "          'rgba(44, 160, 101, 0.5)', \n",
    "          'rgba(255, 65, 54, 0.5)', \n",
    "          'rgba(207, 114, 255, 0.5)', \n",
    "          'rgba(127, 96, 0, 0.5)']\n",
    "\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(x_data, y_data, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints='all',\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Box Plot',\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=False,\n",
    "        #dtick=5,\n",
    "        gridcolor='rgb(255, 255, 255)',\n",
    "        gridwidth=1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30,\n",
    "        b=80,\n",
    "        t=100,\n",
    "    ),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_box = go.Figure(data=traces, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/26.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Outliers on top are probably the peaks in the trend (new license registrations)\n",
    "* Troughs would correspond to the valleys\n",
    "* Median trend is similar to decomposition trend\n",
    "* Spread is quite regular, except for last 2 years (but could be due to lack of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will now try to create an ARIMA model using this data to forecast PC numbers into the future.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a generalization of the simpler AutoRegressive Moving Average and adds the notion of integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n",
    "\n",
    "    AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n",
    "    I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n",
    "    MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The parameters of the ARIMA model are defined as follows:\n",
    "\n",
    "    p: The number of lag observations included in the model, also called the lag order.\n",
    "    d: The number of times that the raw observations are differenced, also called the degree of differencing.\n",
    "    q: The size of the moving average window, also called the order of moving average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we run the ARIMA model on the data, the series has to be tested for stationarity. Although from the decomposition, I believe it's pretty clear it's not a stationary process (the trend varies over time, altering the mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To put it in simpler terms, it has to have a constant mean and variance. And to be clear, stationarity is a property of a process, not a time series.\n",
    "\n",
    "See here: https://en.wikipedia.org/wiki/Stationary_process  \n",
    "See also: https://stats.stackexchange.com/questions/9951/intuitive-explanation-of-stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are several ways to test for stationarity. First we'll apply a simple method.\n",
    "  \n",
    "What we'll do is split the series into 2, and calculate the mean and variance of each group of numbers and compare the values. It's a way of seeing if the avg and variance stay constant in the long run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The % differences seem to be small (3% for mean and 8% for variance)  \n",
    "* But in the case of the variance it's 15 billion vs 14 billion  \n",
    "* The ARIMA model failed for stationarity when I eventually tried to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "series = df_passenger_cars_decomp\n",
    "X = series.values\n",
    "split = 33\n",
    "X1, X2 = X[0:split], X[split:]\n",
    "mean1, mean2 = X1.mean(), X2.mean()\n",
    "var1, var2 = X1.var(), X2.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean1=214667.090909, mean2=207213.878788\n",
      "variance1=15697704021.719006, variance2=14433842867.924702\n",
      "meanDif_pct=0.034720, varDif_pct=0.080512\n"
     ]
    }
   ],
   "source": [
    "print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
    "print('variance1=%f, variance2=%f' % (var1, var2))\n",
    "\n",
    "print('meanDif_pct=%f, varDif_pct=%f' % ((mean1-mean2)/mean1, (var1-var2)/var1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* We've established that the series is non-stationary\n",
    "* We can make the series stationary by first differencing the series \n",
    "* We'll use a statistical test to confirm that the result is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    " \n",
    "# create a differe\n",
    "def difference(dataset):\n",
    "    diff = list()\n",
    "    for i in range(1, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - 1]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    " \n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "\n",
    "# difference data\n",
    "stationary = difference(X)\n",
    "stationary.index = series.index[1:]\n",
    "\n",
    "# check if stationary\n",
    "result = adfuller(stationary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -11.324056\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t5%: -2.917\n",
      "\t1%: -3.558\n",
      "\t10%: -2.596\n"
     ]
    }
   ],
   "source": [
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example outputs the result of a statistical significance test of whether the differenced series is stationary. Specifically, the augmented Dickey-Fuller test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the test statistic value is smaller than the critical value at 1%. This suggests that we can reject the null hypothesis with a significance level of less than 1% (i.e. a low probability that the result is a statistical fluke).\n",
    "\n",
    "Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Unit_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# plot differenced data\n",
    "stationary\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import math \n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Create and style traces\n",
    "trace0_stationary = go.Scatter(\n",
    "    x = stationary.index,\n",
    "    y = stationary.values,\n",
    "    name = 'stationary',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "data_stationary = [trace0_stationary]\n",
    "\n",
    "# Edit the layout\n",
    "layout_stationary = dict(title = 'Stationary Series',\n",
    "              xaxis = dict(title = ''),\n",
    "              yaxis = dict(title = ''),\n",
    "              showlegend=False\n",
    "              )\n",
    "\n",
    "fig_stationary = dict(data=data_stationary, layout=layout_stationary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/32.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig_stationary, filename='stationary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now have a stationary series. In order to determine the parameters for the ARIMA forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import math \n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "acf =  acf(df_passenger_cars_decomp)\n",
    "pacf = pacf(df_passenger_cars_decomp)\n",
    "\n",
    "lags = list(range(0,acf.size+1))\n",
    "\n",
    "upper = [2/math.sqrt(acf.size)] * acf.size\n",
    "lower = [-2/math.sqrt(acf.size)] * acf.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Create and style traces\n",
    "trace0_acf = go.Scatter(\n",
    "    x = lags,\n",
    "    y = acf,\n",
    "    name = 'acf',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "    \n",
    "trace1_acf = go.Scatter(\n",
    "    x = lags,\n",
    "    y = upper,\n",
    "    name = 'upper',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 2,\n",
    "        dash = 'dash'\n",
    "    )\n",
    ")\n",
    "trace2_acf = go.Scatter(\n",
    "    x = lags,\n",
    "    y = lower,\n",
    "    name = 'lower',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 2,\n",
    "        dash = 'dash'\n",
    "    )\n",
    ")\n",
    "\n",
    "data_acf = [trace0_acf, trace1_acf, trace2_acf]\n",
    "\n",
    "# Edit the layout\n",
    "layout_acf = dict(title = 'ACF Plot',\n",
    "              xaxis = dict(title = 'Lag'),\n",
    "              yaxis = dict(title = 'Correlation Coefficient'),\n",
    "              #showlegend=False\n",
    "              )\n",
    "\n",
    "fig_acf = dict(data=data_acf, layout=layout_acf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/28.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig_acf, filename='acf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Highest correlation coefficient observed is at lag 6. The cycle of peaks and valleys tend to repeat at this frequency\n",
    "* This is due to the seasonal pattern in the data: the peaks tend to be 6 months apart and the troughs tend to be 4 and then two months apart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Create and style traces\n",
    "trace0_pacf = go.Scatter(\n",
    "    x = lags,\n",
    "    y = pacf,\n",
    "    name = 'pacf',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "    \n",
    "trace1_pacf = go.Scatter(\n",
    "    x = lags,\n",
    "    y = upper,\n",
    "    name = 'upper',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 2,\n",
    "        dash = 'dash'\n",
    "    )\n",
    ")\n",
    "trace2_pacf = go.Scatter(\n",
    "    x = lags,\n",
    "    y = lower,\n",
    "    name = 'lower',\n",
    "    line = dict(\n",
    "        color = ('rgb(22, 96, 167)'),\n",
    "        width = 2,\n",
    "        dash = 'dash'\n",
    "    )\n",
    ")\n",
    "\n",
    "data_pacf = [trace0_pacf]\n",
    "\n",
    "# Edit the layout\n",
    "layout_pacf = dict(title = 'PACF Plot',\n",
    "              xaxis = dict(title = 'Lag'),\n",
    "              yaxis = dict(title = 'Partial Correlation Coefficient'),\n",
    "              #showlegend=False\n",
    "              )\n",
    "\n",
    "fig_pacf = dict(data=data_pacf, layout=layout_pacf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/30.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(fig_pacf, filename='pacf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACF shows no significant lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Based on the ACF plot, 6 would be a good lag (p) for an ARIMA forecast model\n",
    "* From the stationary plot, 1 order differencing may be effective (d)\n",
    "* We'll experiment with the size of the moving avg window (q) starting with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Predicted=175873.969, Expected=462517\n",
      ">Predicted=469413.121, Expected=79060\n",
      ">Predicted=74475.147, Expected=178420\n",
      ">Predicted=176805.000, Expected=257817\n",
      ">Predicted=258452.333, Expected=198706\n",
      ">Predicted=197726.568, Expected=185778\n",
      ">Predicted=184484.132, Expected=492774\n",
      ">Predicted=499385.000, Expected=76958\n",
      ">Predicted=73008.325, Expected=164856\n",
      ">Predicted=163146.512, Expected=166198\n",
      ">Predicted=164561.167, Expected=172327\n",
      ">Predicted=170870.767, Expected=179714\n",
      ">Predicted=178458.750, Expected=425861\n",
      ">Predicted=430103.578, Expected=72163\n",
      ">Predicted=68624.261, Expected=172907\n",
      ">Predicted=171587.043, Expected=228291\n",
      ">Predicted=228152.375, Expected=194032\n",
      ">Predicted=193197.041, Expected=176820\n",
      ">Predicted=175657.500, Expected=464824\n",
      ">Predicted=469331.431, Expected=68736\n",
      ">Predicted=65539.673, Expected=154562\n",
      ">Predicted=153045.340, Expected=152918\n",
      ">Predicted=151398.981, Expected=159581\n",
      ">Predicted=158210.745, Expected=157314\n",
      ">Predicted=155927.732, Expected=403136\n",
      ">Predicted=406086.719, Expected=65937\n",
      ">Predicted=63023.069, Expected=162228\n",
      ">Predicted=160995.508, Expected=214957\n",
      ">Predicted=214623.867, Expected=180111\n",
      ">Predicted=179212.082, Expected=163357\n",
      ">Predicted=162202.355, Expected=394806\n",
      ">Predicted=397343.476, Expected=66749\n",
      ">Predicted=64120.938, Expected=143643\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt\n",
    "\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "time = series.index[0:int(len(X) * 0.50)]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # predict\n",
    "    model = ARIMA(history, order=(0,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "    print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "\n",
    "\n",
    "test = test[:len(test)-1]\n",
    "predictions = predictions[1:]\n",
    "    \n",
    "# Create and style traces\n",
    "trace0_arima = go.Scatter(\n",
    "    x = time,\n",
    "    y = test,\n",
    "    name = 'test',\n",
    "    #line = dict(color = ('rgb(22, 96, 167)'))\n",
    ")\n",
    "    \n",
    "trace1_arima = go.Scatter(\n",
    "    x = time,\n",
    "    y = predictions,\n",
    "    name = 'predictions',\n",
    "    line = dict(\n",
    "        #color = ('rgb(22, 96, 167)'),\n",
    "        width = 2,\n",
    "        dash = 'dash'\n",
    "    )\n",
    ")\n",
    "\n",
    "data_arima = [trace0_arima, trace1_arima]\n",
    "\n",
    "# Edit the layout\n",
    "layout_arima = dict(title = 'ARIMA Test Plot',\n",
    "              xaxis = dict(title = ''),\n",
    "              yaxis = dict(title = ''),\n",
    "              #showlegend=False\n",
    "              )\n",
    "\n",
    "fig_arima = dict(data=data_arima, layout=layout_arima)\n",
    "    \n",
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2797.392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~churtado_mazepoint/34.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('RMSE: %.3f' % rmse)\n",
    "py.iplot(fig_arima, filename='arima')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
