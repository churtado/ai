{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details:\n",
    "\n",
    "http://192.168.1.123:8998  \n",
    "Livy Server: http://192.168.1.123:8998/ui  \n",
    "Spark Master: http://192.168.1.123:8080/  \n",
    "Spark Magic: https://github.com/jupyter-incubator/sparkmagic/blob/master/examples/Magics%20in%20IPython%20Kernel.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up sparkmagic to be able to communicate without spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's configure our connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manage_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our scala code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "\n",
    "package kMeans\n",
    "\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import org.apache.spark.mllib.clustering.KMeans\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import org.apache.spark.sql.{SQLContext, SparkSession}\n",
    "\n",
    "object kMeans {\n",
    "\n",
    "  def main(args: Array[String]): Unit = {\n",
    "\n",
    "    Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "    Logger.getLogger(\"akka\").setLevel(Level.OFF)\n",
    "\n",
    "    val spark = SparkSession\n",
    "      .builder()\n",
    "      .appName(\"kMeans\")\n",
    "      .master(\"local\")\n",
    "      .getOrCreate()\n",
    "\n",
    "    val sc = spark.sparkContext // doing it this way to be able to import implicits\n",
    "\n",
    "    val sqlContext = new SQLContext(sc)\n",
    "\n",
    "    def readExcel(file: String) = sqlContext.read\n",
    "      .format(\"com.crealytics.spark.excel\")\n",
    "      .option(\"location\", file)\n",
    "      .option(\"useHeader\", \"true\")\n",
    "      .option(\"treatEmptyValuesAsNulls\", \"true\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .option(\"addColorColumns\", \"False\")\n",
    "      .load()\n",
    "\n",
    "    val data = readExcel(\"C:/Users/jorge.robins/Documents/iris.xlsx\")\n",
    "\n",
    "    // data.show(false)\n",
    "\n",
    "    val idPointRDD = data.rdd.map(s => Vectors.dense(s.getDouble(0), s.getDouble(1), s.getDouble(2), s.getDouble(3))).cache()\n",
    "\n",
    "    // pedal width, pedal length, sepal length, sepal width\n",
    "\n",
    "    // Cluster the data into two classes using KMeans\n",
    "    val numClusters = 3\n",
    "    val numIterations = 20\n",
    "    val clusters = KMeans.train(idPointRDD, numClusters, numIterations)\n",
    "\n",
    "    // here is what I added to predict data points that are within the clusters\n",
    "\n",
    "    val WSSSE = clusters.computeCost(idPointRDD)\n",
    "    println(\"Within Set Sum of Squared Errors = \" + WSSSE)\n",
    "\n",
    "    //val predictions = clusters.predict(idPointRDD)\n",
    "    //predictions.collect().foreach(println)\n",
    "\n",
    "    val vectorsAndCluster = idPointRDD.map { point =>\n",
    "      val prediction = clusters.predict(point)\n",
    "      (point.toString, prediction)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataStaging = vectorsAndCluster.map(x=> x._2)\n",
    "dataStaging.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
